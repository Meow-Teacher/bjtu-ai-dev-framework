{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "40475e72bdbe9e92"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 封装数据相关操作\n",
    "- 读取数据并按照空格拆分为token\n",
    "- 构建词汇表\n",
    "- 手动实现Dataset\n",
    "- 手动实现RandomSampler\n",
    "- 手动实现BatchSampler\n",
    "- 手动实现DataLoader"
   ],
   "id": "dd6b5d55fdb24385"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T16:36:06.157506Z",
     "start_time": "2025-05-30T16:36:06.142677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def tokenize_file(input_file):\n",
    "    all_tokens = []\n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        for line_number, line in enumerate(file, 1):\n",
    "            line = line.strip()\n",
    "            tokens = nltk.tokenize.word_tokenize(line)\n",
    "            all_tokens.append(tokens)\n",
    "    # print(f\"Line {line_number}: {all_tokens}\")\n",
    "    return all_tokens\n",
    "\n",
    "\n",
    "# 构建词汇表\n",
    "def build_vocab(sentences, specials=['<pad>', '<unk>', '<sos>', '<eos>']):\n",
    "    vocab = {word: idx for idx, word in enumerate(specials)}\n",
    "    idx = len(specials)\n",
    "\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if word not in vocab:\n",
    "                vocab[word] = idx\n",
    "                idx += 1\n",
    "    return vocab\n",
    "\n",
    "\n",
    "# 手动实现Dataset\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, src_sentences, tgt_sentences, src_vocab, tgt_vocab, max_len=20):\n",
    "        self.src_sentences = src_sentences\n",
    "        self.tgt_sentences = tgt_sentences\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.src_sentences[idx]\n",
    "        tgt = self.tgt_sentences[idx]\n",
    "\n",
    "        # 转换为索引\n",
    "        src_idx = [self.src_vocab.get(word, self.src_vocab['<unk>']) for word in src]\n",
    "        tgt_idx = [self.tgt_vocab['<sos>']] + [self.tgt_vocab.get(word, self.tgt_vocab['<unk>']) for word in tgt] + [\n",
    "            self.tgt_vocab['<eos>']]\n",
    "\n",
    "        # 截断\n",
    "        if len(src_idx) > self.max_len:\n",
    "            src_idx = src_idx[:self.max_len]\n",
    "        if len(tgt_idx) > self.max_len:\n",
    "            tgt_idx = tgt_idx[:self.max_len - 1] + [tgt_idx[-1]]\n",
    "\n",
    "        # 填充\n",
    "        src_padded = src_idx + [self.src_vocab['<pad>']] * (self.max_len - len(src_idx))\n",
    "        tgt_padded = tgt_idx + [self.tgt_vocab['<pad>']] * (self.max_len - len(tgt_idx))\n",
    "\n",
    "        return torch.tensor(src_padded), torch.tensor(tgt_padded)\n",
    "\n",
    "\n",
    "# 手动实现 RandomSampler：随机打乱索引\n",
    "class RandomSampler:\n",
    "    def __init__(self, dataset):\n",
    "        self.indices = list(range(len(dataset)))\n",
    "        random.shuffle(self.indices)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "\n",
    "# 手动实现 BatchSampler：将索引分成批次\n",
    "class BatchSampler:\n",
    "    def __init__(self, sampler, batch_size, drop_last=False):\n",
    "        self.sampler = sampler\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "\n",
    "    def __iter__(self):\n",
    "        batch = []\n",
    "        for idx in self.sampler:\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "        if batch and not self.drop_last:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        total_samples = len(self.sampler)\n",
    "        batches = total_samples // self.batch_size\n",
    "        if not self.drop_last and total_samples % self.batch_size != 0:\n",
    "            batches += 1\n",
    "        return batches\n",
    "\n",
    "\n",
    "# 手动实现 DataLoader 的核心功能\n",
    "class MyDataLoader:\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset,\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            drop_last=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        参数：\n",
    "            dataset: 自定义的 Dataset 对象\n",
    "            batch_size: 每个批次的样本数\n",
    "            shuffle: 是否打乱数据\n",
    "            num_workers: 使用多少个线程加载数据\n",
    "            drop_last: 是否丢弃最后不足 batch_size 的批次\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_workers = num_workers\n",
    "        self.drop_last = drop_last\n",
    "\n",
    "        # 初始化 Sampler 和 BatchSampler\n",
    "        if shuffle:\n",
    "            sampler = RandomSampler(dataset)\n",
    "        else:\n",
    "            sampler = list(range(len(dataset)))  # 顺序采样\n",
    "\n",
    "        self.batch_sampler = BatchSampler(sampler, batch_size, drop_last)\n",
    "\n",
    "    def __iter__(self):\n",
    "        # 使用多线程加载数据\n",
    "        if self.num_workers > 0:\n",
    "            with ThreadPoolExecutor(max_workers=self.num_workers) as executor:\n",
    "                for batch_indices in self.batch_sampler:\n",
    "                    # 提交任务到线程池\n",
    "                    futures = [executor.submit(self.dataset.__getitem__, idx) for idx in batch_indices]\n",
    "                    # 获取结果\n",
    "                    batch = [future.result() for future in futures]\n",
    "                    yield self.collate_fn(batch)\n",
    "        else:\n",
    "            # 单线程加载\n",
    "            for batch_indices in self.batch_sampler:\n",
    "                batch = [self.dataset.__getitem__(idx) for idx in batch_indices]\n",
    "                yield self.collate_fn(batch)  # 按需生成批次数据，从而节省内存并提高效率\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler)\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        # batch 是一个列表，每个元素是 (input, target)\n",
    "        inputs = [item[0] for item in batch]\n",
    "        targets = [item[1] for item in batch]\n",
    "        return torch.stack(inputs), torch.stack(targets)\n"
   ],
   "id": "6af6af60cf39b87",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Transformer 代码实现\n",
    "- 随机种子\n",
    "- 位置编码\n",
    "- 多头注意力机制\n",
    "- 前馈网络\n",
    "- 编码器层\n",
    "- 解码器层\n",
    "- 编码器\n",
    "- 解码器\n",
    "- 模型\n"
   ],
   "id": "15e0b073a0e02fda"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T16:36:12.314683Z",
     "start_time": "2025-05-30T16:36:12.280972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "# 设置随机种子保证可重复性\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "set_seed()\n",
    "\n",
    "\n",
    "# 位置编码\n",
    "# 位置编码的实现方式有两种：\n",
    "# 1. 直接使用sin和cos函数对位置进行编码，这种方式比较简单，但是位置编码的维度比较高，需要注意的是，位置编码的维度需要和模型输入的维度一致。\n",
    "# 2. 使用线性变换对位置进行编码，这种方式需要学习位置编码的权重，但是位置编码的维度比较低，可以和模型输入的维度不一致。\n",
    "# 这里使用第二种方式，使用线性变换对位置进行编码，位置编码的维度为d_model。\n",
    "# 位置编码的公式为：\n",
    "# PE(pos, 2i) = sin(pos / 10000^(2i / d_model))\n",
    "# PE(pos, 2i+1) = cos(pos / 10000^(2i / d_model))\n",
    "# 其中，pos为位置，2i和2i+1分别表示sin和cos函数的参数，d_model为模型输入的\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # 添加batch维度\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)].to(x.device)\n",
    "\n",
    "\n",
    "# 多头注意力机制\n",
    "# 多头注意力机制的实现方式有两种：\n",
    "# 1. 使用PyTorch自带的nn.MultiheadAttention模块，这种方式比较简单，但是需要注意的是，nn.MultiheadAttention模块只能用于Q、K、V的维度相同的情况，如果Q、K、V的维度不相同，需要使用自定义的MultiheadAttention模块。\n",
    "# 2. 使用自定义的MultiheadAttention模块，这种方式需要自己实现Q、K、V的线性变换，以及注意力机制的计算，但是可以实现Q、K、V的维度不相同的情况。\n",
    "# 这里使用第二种方式，使用自定义的MultiheadAttention模块，实现Q、K、V的线性变换，以及注意力机制的计算。\n",
    "# 多头注意力机制的计算方式为：\n",
    "# 1. 将Q、K、V分别进行线性变换，得到Q', K', V'\n",
    "# 2. 计算Q'和K'的注意力得分，注意力得分的计算方式为：\n",
    "# Q'和K'的内积除以根号d_k\n",
    "# 3. 将注意力得分除以100000，然后使用softmax函数进行归一化\n",
    "# 4. 将注意力得分和V'相乘，得到注意力输出\n",
    "# 5. 将注意力输出进行线性变换，得到最终的注意力输出\n",
    "# 6. 将多个注意力输出进行拼接，得到最终的注意力输出\n",
    "# 7. 将最终的注意力输出进行线性变换，得到最终的注意力输出\n",
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        self.W_q = MyLinear(in_features=d_model, out_features=d_model)\n",
    "        self.W_k = MyLinear(d_model, d_model)\n",
    "        self.W_v = MyLinear(d_model, d_model)\n",
    "        self.W_o = MyLinear(d_model, d_model)\n",
    "\n",
    "    # 注意力机制的计算\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        d_k = Q.size(-1)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        attention = torch.nn.functional.softmax(scores, dim=-1)\n",
    "        output = torch.matmul(attention, V)\n",
    "        return output, attention\n",
    "\n",
    "    # 将Q、K、V分别进行线性变换，得到Q', K', V'\n",
    "    def split_heads(self, x):\n",
    "        # 输入x维度 (batch_size, seq_len, d_model)\n",
    "        batch_size, seq_len, d_model = x.size()\n",
    "        # 输出维度 (batch_size, num_heads, seq_len, d_k)\n",
    "        return x.view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "    # 将多个注意力输出进行拼接，得到最终的注意力输出\n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_len, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
    "\n",
    "    # 注意力机制的计算\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "\n",
    "        attention_output, attention_weights = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attention_output))\n",
    "        return output, attention_weights\n",
    "\n",
    "\n",
    "# 前馈网络\n",
    "class FeedForward(torch.nn.Module):\n",
    "    def __init__(self, d_model, dim_feedforward, dropout=0.1):\n",
    "        super(FeedForward, self).__init__()\n",
    "        # TODO 实现不一样\n",
    "        self.linear1 = MyLinear(d_model, dim_feedforward)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.linear2 = MyLinear(dim_feedforward, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.dropout(torch.nn.functional.relu(self.linear1(x))))\n",
    "\n",
    "\n",
    "# 编码器层\n",
    "class EncoderLayer(torch.nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dim_feedforward, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = FeedForward(d_model, dim_feedforward, dropout)\n",
    "        self.norm1 = torch.nn.LayerNorm(d_model)\n",
    "        self.norm2 = torch.nn.LayerNorm(d_model)\n",
    "        self.dropout1 = torch.nn.Dropout(dropout)\n",
    "        self.dropout2 = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        # 自注意力:TODO _weights?\n",
    "        attention_output, attention_weights = self.self_attention(x, x, x, src_mask)\n",
    "        x = self.norm1(x + self.dropout1(attention_output))\n",
    "\n",
    "        # 前馈网络\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout2(ff_output))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# 解码器层\n",
    "class DecoderLayer(torch.nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dim_feedforward, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attention = MultiHeadAttention(d_model, num_heads)\n",
    "        # 编码器-解码器注意力\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = FeedForward(d_model, dim_feedforward, dropout)\n",
    "        self.norm1 = torch.nn.LayerNorm(d_model)\n",
    "        self.norm2 = torch.nn.LayerNorm(d_model)\n",
    "        self.norm3 = torch.nn.LayerNorm(d_model)\n",
    "        self.dropout1 = torch.nn.Dropout(dropout)\n",
    "        self.dropout2 = torch.nn.Dropout(dropout)\n",
    "        self.dropout3 = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        # 自注意力\n",
    "        attention_output, _ = self.self_attention(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout1(attention_output))\n",
    "\n",
    "        # 编码器-解码器注意力\n",
    "        attention_output, _ = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout2(attention_output))\n",
    "\n",
    "        # 前馈网络\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout3(ff_output))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, d_model, num_heads, dim_feedforward, num_layers, max_len, num_classes, dropout=0.1):\n",
    "        \"\"\"\n",
    "        编码器\n",
    "        :param input_dim:\n",
    "        :param d_model:\n",
    "        :param num_heads:\n",
    "        :param dim_feedforward:\n",
    "        :param num_layers:\n",
    "        :param max_len:\n",
    "        :param num_classes: 未来扩展，可应用与分类任务\n",
    "        :param dropout:\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(input_dim, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model=d_model, max_len=max_len)\n",
    "        # Q：为什么用 nn.ModuleList 而不是普通 Python 列表？\n",
    "        # A：\n",
    "        # 1. 自动注册为子模块\n",
    "        #   nn.ModuleList 会将列表中的所有模块（如 nn.Linear、nn.Conv2d 等）自动注册为父模块的子模块（通过 register_module）。\n",
    "        #   普通 Python 列表 不会自动注册模块，导致这些模块的参数无法被 PyTorch 的 state_dict()、parameters() 或优化器识别。\n",
    "        # 2. 参数管理\n",
    "        #   nn.ModuleList 中的模块参数会被自动包含在父模块的 parameters() 中，优化器可以直接访问这些参数。\n",
    "        #   普通列表 中的模块参数会被忽略，导致训练时参数无法更新。\n",
    "        # 3. 模型保存与加载\n",
    "        #   nn.ModuleList 的模块会被自动保存到 state_dict() 中，确保模型加载时参数完整。\n",
    "        #   普通列表 的模块需要单独处理，否则加载模型时会丢失这些模块的状态。\n",
    "        self.layers = torch.nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, dim_feedforward, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.fc_out = MyLinear(d_model, num_classes) if num_classes > 0 else None\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "\n",
    "        if self.fc_out is not None:\n",
    "            x = self.fc_out(x)  # 如果是分类任务\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# 解码器\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, output_dim, d_model, num_heads, dim_feedforward, num_layers, max_len, num_classes, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(output_dim, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_len)\n",
    "        self.layers = torch.nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, dim_feedforward, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.fc_out = MyLinear(d_model, output_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        return self.fc_out(x)\n",
    "\n",
    "\n",
    "class Transformer(torch.nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, num_heads=8, dim_feedforward=2048,\n",
    "                 num_layers=6, max_len=100, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Transformer模型\n",
    "        :param src_vocab_size:\n",
    "        :param tgt_vocab_size:\n",
    "        :param d_model:\n",
    "        :param num_heads:\n",
    "        :param dim_feedforward:\n",
    "        :param num_layers:\n",
    "        :param max_len:\n",
    "        :param dropout:\n",
    "        \"\"\"\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(src_vocab_size, d_model, num_heads, dim_feedforward, num_layers, max_len, 0, dropout)\n",
    "        self.decoder = Decoder(tgt_vocab_size, d_model, num_heads, dim_feedforward, num_layers, max_len, 0, dropout)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(src, src_mask)\n",
    "\n",
    "    def decode(self, tgt, enc_output, src_mask, tgt_mask):\n",
    "        return self.decoder(tgt, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        enc_output = self.encode(src, src_mask)\n",
    "        output = self.decode(tgt, enc_output, src_mask, tgt_mask)\n",
    "        return output\n",
    "\n",
    "\n",
    "# 创建掩码\n",
    "def create_mask(src, tgt):\n",
    "    # 源序列掩码（填充部分）\n",
    "    src_seq_len = src.size(1)\n",
    "    tgt_seq_len = tgt.size(1)\n",
    "    src_mask = (src != 0).unsqueeze(1).unsqueeze(2)  # [batch_size, 1, 1, src_seq_len]\n",
    "\n",
    "    # 目标序列掩码（填充部分 + 自回归）\n",
    "    tgt_pad_mask = (tgt != 0).unsqueeze(1).unsqueeze(2)  # [batch_size, 1, 1, tgt_seq_len]\n",
    "\n",
    "    # 自回归掩码（下三角矩阵）\n",
    "    seq_range = torch.arange(tgt_seq_len).unsqueeze(0).expand(tgt_seq_len, tgt_seq_len).to(tgt.device)\n",
    "    tgt_sub_mask = (seq_range < seq_range.T).unsqueeze(0)  # [1, tgt_seq_len, tgt_seq_len]\n",
    "\n",
    "    tgt_mask = tgt_pad_mask & tgt_sub_mask\n",
    "\n",
    "    return src_mask, tgt_mask\n",
    "\n",
    "\n",
    "class MyLinear(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        \"\"\"\n",
    "        自定义线性层（类似 nn.Linear）\n",
    "        继承nn.Module为了减少call和to的实现\n",
    "\n",
    "        参数：\n",
    "            in_features (int): 输入特征维度\n",
    "            out_features (int): 输出特征维度\n",
    "            bias (bool): 是否使用偏置（默认 True）\n",
    "        \"\"\"\n",
    "        super(MyLinear, self).__init__()\n",
    "        # 初始化权重和偏置（使用随机初始化）\n",
    "        self.weight = torch.nn.Parameter(torch.randn(out_features, in_features))  # 注册为Linear参数\n",
    "        if bias:\n",
    "            self.bias = torch.nn.Parameter(torch.randn(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        前向传播：output = input @ weight.T + bias\n",
    "\n",
    "        参数：\n",
    "            input (torch.Tensor): 输入张量，形状 [batch_size, in_features]\n",
    "\n",
    "        返回：\n",
    "            torch.Tensor: 输出张量，形状 [batch_size, out_features]\n",
    "        \"\"\"\n",
    "        output = torch.matmul(input, self.weight.T)  # 矩阵乘法\n",
    "        if self.bias is not None:\n",
    "            output += self.bias  # 加偏置\n",
    "        return output\n"
   ],
   "id": "7fdad9ff17eccf0e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 训练和测试相关封装\n",
    "- 训练函数\n",
    "- 评估函数"
   ],
   "id": "b99177b96b832ec8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T16:36:20.999543Z",
     "start_time": "2025-05-30T16:36:20.993298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练函数\n",
    "def train(model, dataloader, optimizer, criterion, device, clip=1.0):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (src, tgt) in enumerate(dataloader):\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "        # src维度 ：[batch_size, sequence_length]\n",
    "        # 创建掩码：维度 [batch_size, num_heads, sequence_length, sequence_length]\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_output = tgt[:, 1:]\n",
    "        tgt_mask, _ = create_mask(tgt_input, tgt_output)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, tgt_input, src_mask, tgt_mask)\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        # 计算损失（忽略<pad>）\n",
    "        loss = criterion(output.view(-1, output_dim), tgt_output.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        # 剪裁梯度：防止梯度爆炸，基于参数梯度L2范数对比max_norm\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "# 评估函数\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in dataloader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "            # 创建掩码\n",
    "            src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "            tgt_input = tgt[:, :-1]\n",
    "            tgt_output = tgt[:, 1:]\n",
    "            tgt_mask, _ = transformer.create_mask(tgt_input, tgt_output)\n",
    "\n",
    "            output = model(src, tgt_input, src_mask, tgt_mask)\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            # 计算损失（忽略<pad>）\n",
    "            loss = criterion(output.view(-1, output_dim), tgt_output.view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n"
   ],
   "id": "edd3170105715ef2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 主方法\n",
    "- 训练模型\n",
    "- 测试模型\n",
    "- 评估模型\n",
    "- 绘制训练损失曲线\n",
    "- 评估指标\n"
   ],
   "id": "caa4f474e1af6826"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T16:40:46.982271Z",
     "start_time": "2025-05-30T16:36:24.899516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt  # 添加matplotlib用于绘图\n",
    "import nltk\n",
    "import torch\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    d_model = 128  # 模型嵌入维度\n",
    "    num_heads = 8  # 注意力多头数\n",
    "    dim_feedforward = 512  # 前馈网络隐藏层维度\n",
    "    num_layers = 3  # 编码器和解码器层数\n",
    "    max_len = 20  # 最大序列长度\n",
    "    dropout = 0.1  # dropout比例\n",
    "    batch_size = 64  # 批次大小\n",
    "    num_epochs = 50  # 训练轮数\n",
    "    learning_rate = 0.001  # 学习率\n",
    "\n",
    "    # 检查是否有可用的GPU\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # TODO 编码阶段使用apple mps\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_built() and torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "    # 训练数据\n",
    "    train_en_tokens = tokenize_file('corpora/en.txt')\n",
    "    train_cn_tokens = tokenize_file('corpora/cn.txt')\n",
    "    # 测试数据\n",
    "    test_en_tokens = tokenize_file('corpora/en.test.txt')\n",
    "    test_cn_tokens = tokenize_file('corpora/cn.test.txt')\n",
    "\n",
    "    # 构建词汇表\n",
    "    en_vocab = build_vocab(train_en_tokens + test_en_tokens)\n",
    "    cn_vocab = build_vocab(train_cn_tokens + test_cn_tokens)\n",
    "\n",
    "    # 创建数据集、加载器\n",
    "    train_dataset = MyDataset(train_en_tokens, train_cn_tokens, en_vocab, cn_vocab, max_len)\n",
    "    train_dataloader = MyDataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 初始化模型\n",
    "    model = Transformer(len(en_vocab), len(cn_vocab), d_model, num_heads, dim_feedforward, num_layers,\n",
    "                        max_len, dropout).to(device)\n",
    "\n",
    "    # 定义优化器和损失函数\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=0)  # 忽略<pad>的loss\n",
    "\n",
    "    # 存储训练损失的列表\n",
    "    train_losses = []\n",
    "\n",
    "    # 训练模型\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        train_loss = train(model, train_dataloader, optimizer, criterion, device)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # 记录当前epoch的损失\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Time: {end_time - start_time:.2f}s\")\n",
    "\n",
    "    # 绘制训练损失曲线\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses, marker='o', linestyle='-', color='b')\n",
    "    plt.title('Training Loss Over Epochs')  # 训练过程-损失曲线  不能显示中文，使用英文title\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.xticks(range(0, num_epochs + 1, 100))  # 每100个epoch显示一个刻度\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 测试模型\n",
    "    test_dataset = MyDataset(test_en_tokens, test_cn_tokens, en_vocab, cn_vocab, max_len)\n",
    "    test_dataloader = MyDataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "    # 用于存储评估指标\n",
    "    total_bleu = 0.0\n",
    "    total_tokens = 0\n",
    "    correct_tokens = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in test_dataloader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "            # 创建掩码\n",
    "            src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "            tgt_input = tgt[:, :-1]\n",
    "            tgt_output = tgt[:, 1:]\n",
    "            tgt_mask, _ = create_mask(tgt_input, tgt_output)\n",
    "\n",
    "            output = model(src, tgt_input, src_mask, tgt_mask)\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            # 获取预测结果\n",
    "            predictions = torch.argmax(output, dim=-1)\n",
    "\n",
    "            # 将预测和目标转换为token序列\n",
    "            pred_tokens = predictions.squeeze().tolist()\n",
    "            target_tokens = tgt.squeeze().tolist()\n",
    "\n",
    "            # 过滤掉padding token (0)\n",
    "            pred_tokens = [token for token in pred_tokens if token != 0]\n",
    "            target_tokens = [token for token in target_tokens if token != 0]\n",
    "\n",
    "            # 计算BLEU分数，使用第一个预测作为参考\n",
    "            if len(pred_tokens) > 0 and len(target_tokens) > 0:\n",
    "                # 将token转换为单词\n",
    "                pred_words = [list(cn_vocab.keys())[list(cn_vocab.values()).index(idx)] for idx in pred_tokens]\n",
    "                target_words = [list(cn_vocab.keys())[list(cn_vocab.values()).index(idx)] for idx in target_tokens]\n",
    "\n",
    "                # 因为训练有限，预测句子和参考句子之间重叠较少，在计算BLEU时使用平滑\n",
    "                smoothing = nltk.translate.bleu_score.SmoothingFunction()\n",
    "                bleu = nltk.translate.bleu_score.sentence_bleu([target_words], pred_words,\n",
    "                                                               smoothing_function=smoothing.method1)\n",
    "                total_bleu += bleu\n",
    "\n",
    "            # 计算词级别准确率\n",
    "            # 只比较非padding的部分\n",
    "            min_len = min(len(pred_tokens), len(target_tokens))\n",
    "            correct = sum(1 for i in range(min_len) if pred_tokens[i] == target_tokens[i])\n",
    "            correct_tokens += correct\n",
    "            total_tokens += min_len\n",
    "\n",
    "            # 打印第样本的输入、预测和实际输出  数据较多先不打印\n",
    "            # print(\"Input:\", [list(en_vocab.keys())[list(en_vocab.values()).index(idx)] for idx in src.squeeze().tolist() if idx != 0])\n",
    "            # print(\"Predicted:\", pred_words)\n",
    "            # print(\"Actual:\", target_words)\n",
    "\n",
    "    # 计算平均BLEU分数\n",
    "    avg_bleu = total_bleu / len(test_dataloader) if len(test_dataloader) > 0 else 0.0\n",
    "\n",
    "    # 计算词级别准确率\n",
    "    word_accuracy = correct_tokens / total_tokens if total_tokens > 0 else 0.0\n",
    "\n",
    "    # 评估指标\n",
    "    print(\"Evaluation Metrics:\")\n",
    "    print(f\"Average BLEU Score: {avg_bleu:.4f}\")\n",
    "    print(f\"Word Accuracy: {word_accuracy:.4f}\")\n"
   ],
   "id": "b2afdf63587b4cdf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 38.8512, Time: 5.52s\n",
      "Epoch 2/50, Train Loss: 26.9814, Time: 4.92s\n",
      "Epoch 3/50, Train Loss: 17.5851, Time: 4.90s\n",
      "Epoch 4/50, Train Loss: 12.1024, Time: 4.82s\n",
      "Epoch 5/50, Train Loss: 9.8548, Time: 5.08s\n",
      "Epoch 6/50, Train Loss: 8.8394, Time: 4.91s\n",
      "Epoch 7/50, Train Loss: 8.0950, Time: 4.94s\n",
      "Epoch 8/50, Train Loss: 7.5203, Time: 4.63s\n",
      "Epoch 9/50, Train Loss: 7.1712, Time: 4.52s\n",
      "Epoch 10/50, Train Loss: 6.9758, Time: 4.59s\n",
      "Epoch 11/50, Train Loss: 6.8845, Time: 4.73s\n",
      "Epoch 12/50, Train Loss: 6.8496, Time: 4.66s\n",
      "Epoch 13/50, Train Loss: 6.8326, Time: 5.06s\n",
      "Epoch 14/50, Train Loss: 6.8206, Time: 4.66s\n",
      "Epoch 15/50, Train Loss: 6.8138, Time: 4.49s\n",
      "Epoch 16/50, Train Loss: 6.8075, Time: 5.01s\n",
      "Epoch 17/50, Train Loss: 6.8076, Time: 5.00s\n",
      "Epoch 18/50, Train Loss: 6.8058, Time: 4.83s\n",
      "Epoch 19/50, Train Loss: 6.8045, Time: 5.11s\n",
      "Epoch 20/50, Train Loss: 6.8039, Time: 4.99s\n",
      "Epoch 21/50, Train Loss: 6.8032, Time: 4.88s\n",
      "Epoch 22/50, Train Loss: 6.8055, Time: 5.05s\n",
      "Epoch 23/50, Train Loss: 6.8033, Time: 4.89s\n",
      "Epoch 24/50, Train Loss: 6.8012, Time: 5.06s\n",
      "Epoch 25/50, Train Loss: 6.7997, Time: 5.08s\n",
      "Epoch 26/50, Train Loss: 6.7984, Time: 5.07s\n",
      "Epoch 27/50, Train Loss: 6.7971, Time: 5.03s\n",
      "Epoch 28/50, Train Loss: 6.7966, Time: 5.00s\n",
      "Epoch 29/50, Train Loss: 6.7974, Time: 5.01s\n",
      "Epoch 30/50, Train Loss: 6.7993, Time: 5.07s\n",
      "Epoch 31/50, Train Loss: 6.7978, Time: 5.04s\n",
      "Epoch 32/50, Train Loss: 6.7978, Time: 4.92s\n",
      "Epoch 33/50, Train Loss: 6.7965, Time: 4.98s\n",
      "Epoch 34/50, Train Loss: 6.7964, Time: 4.97s\n",
      "Epoch 35/50, Train Loss: 6.7944, Time: 4.95s\n",
      "Epoch 36/50, Train Loss: 6.7945, Time: 5.08s\n",
      "Epoch 37/50, Train Loss: 6.7946, Time: 4.98s\n",
      "Epoch 38/50, Train Loss: 6.7946, Time: 5.06s\n",
      "Epoch 39/50, Train Loss: 6.7942, Time: 4.93s\n",
      "Epoch 40/50, Train Loss: 6.7940, Time: 4.85s\n",
      "Epoch 41/50, Train Loss: 6.7938, Time: 5.09s\n",
      "Epoch 42/50, Train Loss: 6.7936, Time: 5.13s\n",
      "Epoch 43/50, Train Loss: 6.7929, Time: 5.06s\n",
      "Epoch 44/50, Train Loss: 6.7933, Time: 5.40s\n",
      "Epoch 45/50, Train Loss: 6.7929, Time: 5.53s\n",
      "Epoch 46/50, Train Loss: 6.7928, Time: 5.35s\n",
      "Epoch 47/50, Train Loss: 6.7926, Time: 5.44s\n",
      "Epoch 48/50, Train Loss: 6.7926, Time: 5.21s\n",
      "Epoch 49/50, Train Loss: 6.7925, Time: 6.05s\n",
      "Epoch 50/50, Train Loss: 6.7923, Time: 5.91s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Average BLEU Score: 0.0094\n",
      "Word Accuracy: 0.0717\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
